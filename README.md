# awesome-pose
* curated list for pose estimation
* 3DPW models : https://paperswithcode.com/sota/3d-human-pose-estimation-on-3dpw

## Multi-View - Human Pose Estimation, Human Mesh Recovery
* <b>2019/09</b> Cross View Fusion for 3D Human Pose Estimation [[paper]](https://arxiv.org/pdf/1909.01203.pdf) [[code]](https://github.com/microsoft/multiview-human-pose-estimation-pytorch)
> - Multi-View ì´ë¯¸ì§€ë“¤ì„ CNNìœ¼ë¡œ ê°ê° heatmap ì¶”ì¶œí•œ ë’¤ fusioní•˜ì—¬ ê° viewì˜ íˆíŠ¸ë§µì´ ë‹¤ë¥¸ ë·°ì˜ ì´ì ì„ ì–»ë„ë¡ í•¨.
> - Multi-View 2D poseì—ì„œ 3D í¬ì¦ˆë¥¼ ë³µêµ¬í•˜ë„ë¡ ì²˜ë¦¬
> - ì—¬ëŸ¬ ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ê´€ì ˆ ìœ„ì¹˜ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •
> - ê° ê´€ì ˆì„ ê°œë³„ì ìœ¼ë¡œ refine(ìˆ˜ì •)í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ê³µê°„ì  ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ëª¨ë“  ê´€ì ˆì„ ë™ì‹œì— refineí•¨
* <b>2021/11</b> Direct Multi-view Multi-person 3D Human Pose Estimation [[paper]](https://arxiv.org/pdf/2111.04076.pdf) [[code]](https://github.com/sail-sg/mvp)
* <b>2022/01</b> AirPose: Multi-View Fusion Network for Aerial 3D Human Pose and Shape Estimation [[paper]](https://arxiv.org/pdf/2201.08093.pdf) [[code]](https://github.com/robot-perception-group/AirPose)
> - ì™¸ë¶€ì ìœ¼ë¡œ ë³´ì •ë˜ì§€ ì•Šì€ ì—¬ëŸ¬ ëŒ€ì˜ ë¹„í–‰ ì¹´ë©”ë¼ë¡œ ìº¡ì²˜í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒì˜ ìì„¸ì™€ ëª¨ì–‘ì„ ì¶”ì •í•˜ëŠ” ë°©ë²•(AirPose), SMPL-X ì‚¬ìš©, ë” ì¢‹ì€ mocap í’ˆì§ˆì´ í•„ìš”í•œ ì˜¤í”„ë¼ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ìµœì í™” ê¸°ë°˜ì˜ í›„ì²˜ë¦¬ ë°©ë²•(AirPose+) ì œì•ˆ
* <b>WACV 2021</b> 3D Human Pose and Shape Estimation Through Collaborative Learning and Multi-view Model-fitting [[paper]](https://openaccess.thecvf.com/content/WACV2021/papers/Li_3D_Human_Pose_and_Shape_Estimation_Through_Collaborative_Learning_and_WACV_2021_paper.pdf) [[code]](https://github.com/leezhongguo/MVSPIN_NEW)
> - Multi-View ê¸°ë°˜ì˜ íšŒê·€ í•™ìŠµ ë£¨í”„ë¥¼ ì´ìš©í•´ì„œ 3D human pose, shape estimation. 
> - ë¨¼ì € CNNìœ¼ë¡œ multi-view ì´ë¯¸ì§€ì—ì„œ ê°ê° SMPL shape, poseë¥¼ íšŒê·€í•œ ë’¤, ê·¸ ê°’ë“¤ì„ ì´ˆê¸°ê°’ìœ¼ë¡œ í™œìš©í•˜ì—¬ multi-view ì´ë¯¸ì§€ì— ë™ì‹œì— ìµœì í™”ë˜ë„ë¡ í•˜ëŠ” ë°©ë²•.
* <b>2021/10</b> Dynamic Multi-Person Mesh Recovery From Uncalibrated Multi-View Cameras [[paper]](https://arxiv.org/pdf/2110.10355.pdf) [[code]](https://github.com/boycehbz/DMMR)
> - ë³´ì •ë˜ì§€ ì•Šì€ Multi-View ì¹´ë©”ë¼(ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ê°€ ì•Œë ¤ì§€ì§€ ì•Šì€ ìƒíƒœ)ë¥¼ ì´ìš©í•œ Dynamic(ì›€ì§ì´ëŠ” ë™ì‘) ì—¬ëŸ¬ ì‚¬ëŒë“¤ì˜ Mesh ë³µì› ë°©ë²•(ë¬¼ë¦¬ì  ì¼ê´€ì„±ì„ ì´ìš©í•´ì„œ í•´ê²°). 
> - Encoder-Decoder ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê³ , Encoderì™€ Decoder ë‚´ë¶€ì—ëŠ” GRU ì‚¬ìš©í•¨.
* <b>2021/06</b> Part-aware Measurement for Robust Multi-View Multi-Human 3D Pose Estimation and Tracking [[paper]](https://arxiv.org/pdf/2106.11589.pdf) [[code]](https://github.com/B10532021/Part-Aware_Measurement_for_3D_Pose_Estimation_and_Tracking)
> - Multi-View ê¸°ë°˜ì˜ ì¹´ë©”ë¼ ìƒí™©ì—ì„œ Object Detection(YOLOv3)ì„ í†µí•´ ì‚¬ëŒë§Œ ì¶”ì¶œí•œ ë’¤, 2D Pose Estimation(HRNet) ì²˜ë¦¬, ê·¸ í›„ ì‹œê°„ì  ì¼ê´€ì„±(temporal correspondences)ì„ ì´ìš©í•´ì„œ ëª¨ë“  ë·°ì—ì„œ ë™ì¼í•œ 3D poseë¡œ ë‚˜ì˜¤ë„ë¡ ìµœì í™” ì‘ì—… ì§„í–‰
> - êµ¬ì²´ì ìœ¼ë¡œ 2D-3D ì—°ê´€ì„ ìœ„í•œ Part-Aware(ë¶€ë¶„ ì¸ì‹) ì¸¡ì •ê³¼ ì¬êµ¬ì„± ê³¼ì •ì—ì„œ 2D Outlier(ì´ìƒì¹˜)ì— ëŒ€ì²˜í•  ìˆ˜ ìˆëŠ” í•„í„°ë¥¼ ì œì•ˆí•¨. (ëª©ì ì€ 3D Human Pose Estimation)
* <b>2021/04</b> Multi-View Multi-Person 3D Pose Estimation with Plane Sweep Stereo [[paper]](https://arxiv.org/pdf/2104.02273.pdf) [[code]](https://github.com/jiahaoLjh/PlaneSweepPose)
> - ë™ê¸°í™”(synchronized)ë˜ê³  ë³´ì •ëœ(calibrated) ìƒíƒœì˜ multi-view ì¹´ë©”ë¼ ì‚¬ìš©
> - ê° ì¹´ë©”ë¼ ë·°ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ HRNet ëª¨ë¸ì„ ì´ìš©í•œ 2D Pose ì¶”ì • ì§„í–‰, ê·¸ í›„ multi reference viewì—ì„œ 2D pose ê°ì§€ë¥¼ í™œìš©í•˜ì—¬ target camera view ì•„ë˜ì— ìˆëŠ” Joints 2D í›„ë³´ì— ëŒ€í•´ depth íšŒê·€(regression)ë¥¼ ìˆ˜í–‰í•¨
* <b>2021/09</b> Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering [[paper]](https://arxiv.org/pdf/2109.07448.pdf) [[code]](https://github.com/YoungJoongUNC/Neural_Human_Performer)
> - Temporal Transformer, Multi-View Transformer, NeRF (Clothed Body Mesh)

## Human Mesh Recovery
* <b>2020/08</b> frankmocap(3d body+hand motion capture) : Fast Monocular 3D Hand and Body Motion Capture by Regression and Integration [[paper]](https://arxiv.org/abs/2008.08324)[[code]](https://github.com/facebookresearch/frankmocap)[[skeleton info]](https://github.com/facebookresearch/frankmocap/blob/master/docs/joint_order.md)
* <b>2020/08</b> I2L-MeshNet : Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image [[paper]](https://arxiv.org/abs/2008.03713)[[code]](https://github.com/mks0601/I2L-MeshNet_RELEASE)
* <b>2020/08</b> ROMP: Monocular, One-stage, Regression of Multiple 3D People [[paper]](https://arxiv.org/abs/2008.12272) [[code]](https://github.com/Arthur151/ROMP) : ì‹¤ë°ì´í„° í™•ì¸ ì‹œ ì¤€ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
* <b>2021/04</b> MeshGraphormer [[paper]](https://arxiv.org/abs/2104.00272) [[code]](https://github.com/microsoft/meshgraphormer) : Microsoftì˜ ì´ì „ ë…¼ë¬¸ì¸ METRO ë…¼ë¬¸ì— GCNNì„ ì¶”ê°€í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ ë…¼ë¬¸ì…ë‹ˆë‹¤. ì‹¤ë°ì´í„°ë¡œ í™•ì¸ ì‹œ íìƒ‰ì— ì·¨ì•½í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤.
* <b>2021/04</b> PARE: Part Attention Regressor for 3D Human Body Estimation [[paper]](https://arxiv.org/abs/2104.08527) [[code]](https://github.com/mkocabas/PARE) : ì‹¤ë°ì´í„° í™•ì¸ ì‹œ ì¤€ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
* <b>2021/10</b> Learning to Regress Bodies from Images using Differentiable Semantic Rendering
 [[code]](https://github.com/saidwivedi/DSR) [[paper]](https://arxiv.org/abs/2110.03480)
* <b>2021/11</b> Out-of-Domain Human Mesh Reconstruction via Dynamic Bilevel Online Adaptation 
[[paper]](https://arxiv.org/abs/2111.04017) [[code]](https://github.com/syguan96/dynaboa) [[project]](https://sites.google.com/view/dynaboa)
> - 2021/12 ê¸°ì¤€ 3DPW SOTA, unsupervised online adaption ê¸°ë°˜ì˜ ëª¨ë¸ì´ë¼ëŠ” ì ì—ì„œ ê°œë…ì ìœ¼ë¡œ ì¢‹ì§€ë§Œ, í•´ë‹¹ ë„ë©”ì¸ì— ëŒ€í•œ skeleton ë°ì´í„°ê°€ í•­ìƒ í•„ìš”í•˜ê³ , í•´ë‹¹ ë°ì´í„°ë¡œ í•™ìŠµ ì§„í–‰ í›„ ì¶”ë¡ í•˜ëŠ” ëŠë‚Œì…ë‹ˆë‹¤.
> - ì‹¤ë°ì´í„°ë¡œ í™•ì¸ ì‹œ ê²°ê³¼ê°€ ì¢‹ì§€ ì•Šê³ , ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦½ë‹ˆë‹¤.
* <b>2020/10</b> Invariant Representation Learning for Infant Pose Estimation with Small Data
 [[paper]](https://arxiv.org/abs/2010.06100) [[code]](https://github.com/ostadabbas/Infant-Pose-Estimation)
* <b>2021/06</b> Animatable Neural Radiance Fields from Monocular RGB Videos [[paper]](https://arxiv.org/pdf/2106.13629.pdf) [[code]](https://github.com/JanaldoChen/Anim-NeRF)
> - NeRF ë° SMPL parameter ê³µë™ ìµœì í™”
> - Animatable neural radiance fields (animatable NeRF), F : 3D position(x,y,z), shape ğ›½, pose ğœƒë¥¼ color c =(r,g,b) ì™€ density Ïƒë¡œ ë§¤í•‘í•¨
> - ![Equation1](./anim_nerf_eq1.png)
> - ìœ„ì˜ ì‹ì—ì„œ D(x, ğœƒ, ğ›½)ëŠ” ë‹¤ë¥¸ í”„ë ˆì„ë“¤ê°„ì˜ ì‚¬ëŒ ì›€ì§ì„ë“¤ì„ ë‹¤ë£¨ê¸° ìœ„í•´, ê´€ì°° ì˜ì—­ ë‚´ì˜ 3D position x = (x,y,z)ë¥¼ í‘œì¤€ ì˜ì—­(canonical space)ì˜ x_0 = (x0, y0, z0)ë¡œ ë³€í˜•í•œë‹¤. NeRFì˜ ì‹œì (view) ì˜ì¡´ì„±ì€ ì² ì´ë‚˜ ìœ ë¦¬ì— ë¹„ì¶˜ ê²ƒê³¼ ê°™ì€ ê±°ìš¸ ë°˜ì‚¬ë¥¼ ì£¼ë¡œ ë‹¤ë£¬ë‹¤. í•˜ì§€ë§Œ ì‚¬ëŒì˜ í”¼ë¶€ì™€ ì˜·ë“¤ì€ ë¶„ì‚°ë˜ì–´ ìˆê¸° ë•Œë¬¸ì—(ë§¤ìš° ë‹¤ì–‘í•´ì„œ ê·¸ëŸ° ê²ƒ ê°™ìŠµë‹ˆë‹¤), ì´ ë…¼ë¬¸ì—ì„œëŠ” ì‹œì  ë°©í–¥(viewing direction)ì„ ì œê±°í•œë‹¤. 
> - A Pose Sequence(í•œë°”í€´ ë„ëŠ” ì˜ìƒ, Aí¬ì¦ˆë¡œ)ë¡œ í•™ìŠµí•´ì„œ ê·¸ ì‚¬ëŒì˜ ì˜·, shape ë‹¤ ë”°ì„œ ë‹¤ë¥¸ ìì„¸ë¡œ ë³€í˜• ê°€ëŠ¥í•˜ë„ë¡ í•¨
> - ![Figure8](./fig8_2106.png)
> - í•œê³„ì  : ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ìˆ˜í–‰ìê°€ ì²œì²œíˆ ëª¸ì„ ëŒë¦¬ê³  ê°„ë‹¨í•œ í¬ì¦ˆ(A-Pose)ë¥¼ ì·¨í•˜ë©´ì„œ ì˜·ì´ ê³ í’ˆì§ˆ ë Œë”ë§ì„ ìœ„í•´ ëª¸ì— ê±°ì˜ ê³ ì •ë˜ë„ë¡ í•´ì•¼í•œë‹¤. 
> - í•œ ì¥ë©´ì— í•™ìŠµëœ ëª¨ë“  NeRFê¸°ë°˜ ë°©ë²•ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë³´ì´ì§€ ì•ŠëŠ” ë¶€ë¶„ì€ ì¬êµ¬ì„±ì´ ì–´ë ¤ì›Œì„œ input videoì— ìµœëŒ€í•œ ë·°ê°€ ë‹´ê²¨ìˆì–´ì•¼í•¨.
* <b>2022</b> Accurate 3D Body Shape Regression using Metric and Semantic Attributes [[paper]](https://ps.is.mpg.de/uploads_file/attachment/attachment/691/00928.pdf) [[code]](https://github.com/muelea/shapy)
> - single image + ì‹ ì²´ ì†ì„± ìˆ˜ì¹˜ê°’(í‚¤, ëª¸ë¬´ê²Œ, ê°€ìŠ´ë‘˜ë ˆ, í—ˆë¦¬ë‘˜ë ˆ ë“±)ì„ ëª¨ë¸ ì—ì´ì „ì‹œ ë°ì´í„°, ìœ ëª…ì¸ ë°ì´í„°ë¥¼ í™œìš©í•´ì„œ ìˆ˜ì§‘í•´ì„œ í•™ìŠµì— ì´ìš©í•¨
> - ì¢€ ë” shapeì´ ì˜ ë‚˜ì˜¤ë„ë¡ ë§Œë“  ëª¨ë¸
* <b>2021</b> PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop [[paper]](https://arxiv.org/pdf/2207.06400v1.pdf) [[code]](https://github.com/HongwenZhang/PyMAF)
> - 2021ë…„ Body Meshë¥¼ ë‹¤ë¤˜ë˜ PyMAFì—ì„œ ì—…ê·¸ë ˆì´ë“œí•´ì„œ Full-Bodyë¥¼ ë‹¤ë£¨ëŠ” PyMAF-Xê°€ 2022ë…„ 7ì›” ë…¼ë¬¸ ë°œí‘œëœ ìƒíƒœì´ê³ , ì½”ë“œëŠ” ì•„ì§ ì—…ë°ì´íŠ¸ê°€ ë˜ì§€ ì•Šì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
> - 3D Body Pose ê³„ì—´ ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í•˜ëŠ”, ê´€ì ˆì´ ë’¤ë¡œ ê°€ëŠ” ë™ì‘ ë¹¼ê³ ëŠ” ê±°ì˜ ì˜ ë©ë‹ˆë‹¤. íìƒ‰ì´ ë§ì€ ì‚¬ì´ë“œë·° ë™ì‘, ì „ë©´ë¶€ ìš´ë™ ì˜ìƒ


## Human Mesh Recovery + Texture
* <b>2021/09</b> Texformer: 3D Human Texture Estimation from a Single Image with Transformers
 [[paper]](https://arxiv.org/abs/2109.02563) [[code]](https://github.com/xuxy09/Texformer)
* <b>2021/12</b> ICON: Implicit Clothed humans Obtained from Normals [[paper]](https://arxiv.org/pdf/2112.09127.pdf) [[code]](https://github.com/YuliangXiu/ICON)
* <b>2021/05</b> Animated 3D Human Avatars from a Single Image with GAN-based Texture Inference [[paper]](https://www.researchgate.net/profile/Zhong-Li-16/publication/348875382_Animated_3D_Human_Avatars_from_a_Single_Image_with_GAN-based_Texture_Inference/links/60a692cb299bf1031f06f4c9/Animated-3D-Human-Avatars-from-a-Single-Image-with-GAN-based-Texture-Inference.pdf) : ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ GANì„ ì´ìš©í•´ Textureë¥¼ ë§Œë“¤ë„ë¡ í•˜ëŠ” ë…¼ë¬¸
* <b>2022/01</b> HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video [[paper]](https://arxiv.org/pdf/2201.04127.pdf) [[project]](https://grail.cs.washington.edu/projects/humannerf/) : Google Researchì—ì„œ ë°œí‘œí•œ ë…¼ë¬¸ìœ¼ë¡œ monocular videoë¥¼ inputìœ¼ë¡œ ë°›ì•„ì„œ free-viewpoint rendering(3Dë¡œ ê°ë„ ì œí•œ ì—†ì´ ë³¼ ìˆ˜ ìˆë„ë¡)ì´ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“  ë…¼ë¬¸

## Clothed Body Mesh
* <b>2021/03</b> SMPLicit: Topology-aware Generative Model for Clothed People
 [[paper]](https://arxiv.org/pdf/2103.06871.pdf) [[code]](https://github.com/enriccorona/SMPLicit)
> - ê¸°ì¡´ SMPL ëª¨ë¸ì˜ topì— clothes layerë¥¼ ì–¹ì–´ì„œ ë§Œë“  ëª¨ë¸ë¡œ ê¸°ì¡´ SMPLê³¼ ë³„ê°œì˜ ëª¨ë¸ íŒŒì¼ì´ ë”°ë¡œ ìˆìŒ. pifuHD, tex2Shapeì— ë¹„í•´ ë” ì •êµí•œ ì˜·ì˜ ì§ˆê° í‘œí˜„ ê°€ëŠ¥ 
> - imageì— fittingí•˜ëŠ” ì½”ë“œ([[fit_SMPLicit]](https://github.com/enriccorona/SMPLicit/tree/main/fit_SMPLicit))ê°€ Repo ë‚´ì— ë³„ë„ë¡œ ì¡´ì¬í•¨
> - [[Self-Correction-Human-Parsing]](https://github.com/PeikeLi/Self-Correction-Human-Parsing)(Cloth segmentation ì´ìš© ì‹œ lip ë°ì´í„°ì…‹,íŒ”ë ˆíŠ¸ ì œê±°í•œ ë°ì´í„°ë¡œ ì´ìš© ê°€ëŠ¥)
 > - cloth segmentation, human instance segmenatation, smpl prediction 3ê°œ ëª¨ë¸ ê²°ê³¼ ì·¨í•© í›„ ì´ë¯¸ì§€ 1ì¥ fitting ì‹œ 4ë¶„ ì •ë„ ì‹œê°„ ì†Œìš”
 > - ë…¼ë¬¸ ì´ë¯¸ì§€ì²˜ëŸ¼ ìƒ‰ìƒìˆëŠ” ì¶œë ¥ê°’ ë§Œë“œë ¤ë©´ modeë¥¼ renderingí•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ ì‹œ rgbë¡œ ë³€ê²½ í•„ìš”
* <b>2020/04</b> BCNet: Learning Body and Cloth Shape from A
Single Image [[paper]](https://github.com/jby1993/BCNet) [[code]](https://github.com/jby1993/BCNet)
> - ResNet ê¸°ë°˜ ëª¨ë¸ë¡œ feature ì¶”ì¶œí•´ì„œ garments(ì˜·), smpl params(beta, pose, trans) ì¶”ì¶œí•˜ëŠ” ë ˆì´ì–´ë¡œ ì—°ê²°í•´ì„œ ì²˜ë¦¬í•¨
> - garment classification : ìœ„ì˜ featureë¥¼ ì´ìš©í•´ì„œ ìƒì˜ì˜ ê²½ìš° FC Layerë¡œ 2ê°œ(ë°˜íŒ”, ê¸´íŒ”), í•˜ì˜ì˜ ê²½ìš° 4ê°œ(ë°”ì§€, ì§§ì€ë°”ì§€, ì¹˜ë§ˆ, ì§§ì€ì¹˜ë§ˆ)ë¡œ ë¶„ë¥˜í•˜ë„ë¡ í•œë‹¤.
> - ì˜· ë¶€ë¶„ì˜ verticesë¥¼ ë§Œë“¤ ë•ŒëŠ” SMPL Parameterì¸ Beta, Poseì™€ Î±(ìƒì„¸ ì˜ë¥˜ë³„ PCA ê³„ìˆ˜ê°’), D(ë‹¤ì–‘í•œ í¬ì¦ˆ / ì˜·ê³¼ ëª¸ì˜ ë‹¤ì–‘í•œ ìƒí˜¸ì‘ìš©ì— ë”°ë¥¸ Variationì„ captureí•˜ê¸° ìœ„í•œ ë³€ìˆ˜)ë¥¼ ì‚¬ìš©

## 3d Pose estimation (3d skeleton)
* <b>2017/05</b> ColorHandPose3D : Learning to Estimate 3D Hand Pose from Single RGB Images
 [[code]](https://github.com/lmb-freiburg/hand3d)
* <b>2018/11</b> VideoPose3D : 3D human pose estimation in video with temporal convolutions and semi-supervised training [[paper]](https://arxiv.org/abs/1811.11742)[[code]](https://github.com/facebookresearch/VideoPose3D)

## 2d Pose estimation
* <b>2018/12</b> OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation [[paper]](https://arxiv.org/abs/1812.08008) [[code]](https://github.com/CMU-Perceptual-Computing-Lab/openpose)
* <b>2020/12</b> TransPose: Keypoint Localization via Transformer [[paper]](https://arxiv.org/pdf/2012.14214.pdf) [[code]](https://github.com/yangsenius/TransPose) : Transformer ê¸°ë°˜ì˜ 2D Pose Estimation (Openposeë³´ë‹¤ ì„±ëŠ¥ ì¢‹ìŒ)

## dataset
* Human Foot Keypoint Dataset(2d) : [[url]](https://cmu-perceptual-computing-lab.github.io/foot_keypoint_dataset/)[[code]](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train)
* <b>2020/07</b> Coco Whole Body : Whole-Body Human Pose Estimation in the Wild [[paper]](https://arxiv.org/abs/2007.11858)[[code]](https://github.com/jin-s13/COCO-WholeBody)

## etc
* <b>2018/12</b> PoseFix : Model-agnostic General Human Pose Refinement Network [[paper]](https://arxiv.org/abs/1812.03595)[[code]](https://github.com/mks0601/PoseFix_RELEASE)
* Bodyvisualizer(3d mesh by gender, height, weight, etc) : [[url]](https://bodyvisualizer.com/male.html)
* <b>2022/06</b> OSSO: Obtaining Skeletal Shape from Outside (Mesh Skeleton visualization) - Mesh ply íŒŒì¼ ì£¼ì–´ì§„ ìƒíƒœì—ì„œ skeleton í˜•íƒœë¡œ ë½‘ì•„ë‚¸ë‹¤ : [[paper]](https://download.is.tue.mpg.de/osso/OSSO.pdf)[[code]](https://github.com/MarilynKeller/OSSO)
<img src="https://github.com/MarilynKeller/OSSO/raw/main/figures/skeleton_results.png" style="height:200px">

